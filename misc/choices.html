<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>choices</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>
    <img src="../images/csg4ed-small.png" alt="Enhancing Social Good in Computing"
    <!-- Site navigation menu -->

    <ul class="navbar">
        <li><a href="../index.html">Home page</a>
        <li><a href="topic.html">Technology/Topic</a>
        <li><a href="opportunities.html">Opportunities</a>
        <li><a href="risks.html">Risks</a>
        <li><a href="choices.html">Choices</a>
        <li><a href="ethics.html">Ethical Reflections</a>
        <li><a href="references.html">References</a>
        <li><a href="process.html">Process Support</a>
    </ul>

    <!-- Main content -->
    <h1>Technology Choices</h1>

    <!--The page or area describing the choices available to us through or by your chosen technology/topic-->
    </ul><p>
    When thinking about our choices with Artificial Intelligence, the choices we have are essentially only limited by our current capabilities.<br>
    We can develop deep learning systems that allows the systems to collaborate with each other, mimicking the human learning.<br />
    We can develop machine learning systems to require a smaller number of examples to train the machine learning algorithm.<br /><br />

    “Misaligned or confused and conflated goals of an AI are going to be a significant concern of the future, as the AI will be extremely good at achieving its goals, but those goals may not represent what we wanted.”<br /><br />

    One choice we must make is to develop the machine learning systems to where an AI can explain the logic behind their judgement. 
    By doing so we then become able to understand where the algorithm fails and correct this. According to Baecker Ronald M. (2019), Computer scientists Jenna Burell and Ed 
    Felton have noted several reasons as to why an algorithm may not be explainable, one of these reasons being that the logic may not be justifiable. This is often referred 
    to as the "Black Box" problem (Kuang C. (2017)). Also mentioned in the article written by Kuang, is the idea that in order for an AI to be able to defend it's reasonings,
    it needs more AI. The example used, was allowing an AI to teach itself how to describe a picture. The AI would have two deep neural networks, one for recognizing images 
    and another for translating languages. They then used thousands of images with captions as the training samples. The image recognition network would process the images 
    while the second network would slowly become to associate certain words and images. Then with these networks, there would be another network dedicated to narrating this 
    process, allowing the AI to explain and justify it's conclusions. This example of visualising explanations is also explained in more detail by Hendricks (2016). 
    This method works for simple problems. However, if we can refine it enough to work for complex problems we face today, it would be extremely useful in increasing our 
    trust in AI made decisions.<br/><br/>
    
    Another choice for development would be to create deep learning systems that can collaborate with eachother. This stems from the fact that to create a deep learning system, there would be large
    amounts of data needed, and some companies don't have access to such large quantities required. To overcome this, it would be more effective and efficient for our 
    systems to require a smaller set of samples in order to train the algorithms required for a task. One way of incorporating the smaller data sets, would be for deep
    learning systems to pass on certain bits of information, referred to by Vincent (2016), as progressive neural networks. The only drawback noted in a paper by Hadsell (2016),
    is that, the more systems are chained together, the harder it becomes to control, and that is when the tasks performed are similar. Doing multiple vastly different tasks
    would make it near impossible to influence. 

<p>

    <!-- Sign and date the page, it's only polite! -->
    <address>
        Made 1 March 2021<br>
        by Tony Clear.
    </address>

    <p><em>thanks to W3C for tutorial and adapted code from <a href="https://www.w3.org/Style/Examples/011/firstcss.en.html">Style Examples</a></p></em>
    <p><em>also thanks to WDN for HTML and CSS resources and any adapted code snippets from <a href="https://developer.mozilla.org/en-US/docs/Web">Mozilla Developer Network</a></p></em
</html>